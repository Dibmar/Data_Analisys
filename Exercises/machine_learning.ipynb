{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0fa281aee82f4477ae52abf752de28cd069eade5886616c2da4ed23d36079b5d2",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "fa281aee82f4477ae52abf752de28cd069eade5886616c2da4ed23d36079b5d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 31 entries, 0 to 30\nData columns (total 16 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         31 non-null     object \n 1   cod_unit     31 non-null     object \n 2   cod_faction  31 non-null     object \n 3   cod_spec     8 non-null      object \n 4   movement     31 non-null     int64  \n 5   w_s          31 non-null     int64  \n 6   b_s          31 non-null     int64  \n 7   strenght     31 non-null     int64  \n 8   toughness    31 non-null     int64  \n 9   wounds       31 non-null     int64  \n 10  initiative   31 non-null     int64  \n 11  attacks      31 non-null     int64  \n 12  leadership   31 non-null     int64  \n 13  save         31 non-null     int64  \n 14  equip_cod    0 non-null      float64\n 15  cost         31 non-null     int64  \ndtypes: float64(1), int64(11), object(4)\nmemory usage: 4.0+ KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 36 entries, 0 to 35\nData columns (total 16 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         36 non-null     object \n 1   cod_unit     36 non-null     object \n 2   cod_faction  36 non-null     object \n 3   cod_spec     0 non-null      float64\n 4   movement     36 non-null     int64  \n 5   w_s          36 non-null     int64  \n 6   b_s          36 non-null     int64  \n 7   strenght     36 non-null     int64  \n 8   toughness    36 non-null     int64  \n 9   wounds       36 non-null     int64  \n 10  initiative   36 non-null     int64  \n 11  attacks      36 non-null     int64  \n 12  leadership   36 non-null     int64  \n 13  save         36 non-null     int64  \n 14  equip_cod    0 non-null      float64\n 15  cost         34 non-null     float64\ndtypes: float64(3), int64(10), object(3)\nmemory usage: 4.6+ KB\nNone\n----------\nNone\n"
     ]
    }
   ],
   "source": [
    "path_1 = 'C:\\\\Users\\\\Servando\\\\Documents\\\\Project Hammer\\\\Datos\\\\enanos.csv'\n",
    "path_2 = 'C:\\\\Users\\\\Servando\\\\Documents\\\\Project Hammer\\\\Datos\\\\elfos_oscuros.csv'\n",
    "\n",
    "\n",
    "dwarfs = pd.read_csv(path_1, sep=';')\n",
    "d_elves = pd.read_csv(path_2, sep=';')\n",
    "\n",
    "print(f'{dwarfs.info()}\\n{\"-\" * 10}\\n{d_elves.info()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              name cod_unit cod_faction  cod_spec  movement  w_s  b_s  \\\n",
       "0  Pr�ncipe Oscuro    LORDM       DELFS       NaN        12    7    6   \n",
       "\n",
       "   strenght  toughness  wounds  initiative  attacks  leadership  save  \\\n",
       "0         4          3       3           8        4          10     0   \n",
       "\n",
       "   equip_cod   cost  \n",
       "0        NaN  125.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>cod_unit</th>\n      <th>cod_faction</th>\n      <th>cod_spec</th>\n      <th>movement</th>\n      <th>w_s</th>\n      <th>b_s</th>\n      <th>strenght</th>\n      <th>toughness</th>\n      <th>wounds</th>\n      <th>initiative</th>\n      <th>attacks</th>\n      <th>leadership</th>\n      <th>save</th>\n      <th>equip_cod</th>\n      <th>cost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pr�ncipe Oscuro</td>\n      <td>LORDM</td>\n      <td>DELFS</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>7</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>125.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "d_elves.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 65 entries, 0 to 35\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         65 non-null     object \n 1   cod_unit     65 non-null     object \n 2   cod_faction  65 non-null     object \n 3   movement     65 non-null     int64  \n 4   w_s          65 non-null     int64  \n 5   b_s          65 non-null     int64  \n 6   strenght     65 non-null     int64  \n 7   toughness    65 non-null     int64  \n 8   wounds       65 non-null     int64  \n 9   initiative   65 non-null     int64  \n 10  attacks      65 non-null     int64  \n 11  leadership   65 non-null     int64  \n 12  save         65 non-null     int64  \n 13  cost         65 non-null     float64\ndtypes: float64(1), int64(10), object(3)\nmemory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "whole = pd.concat([dwarfs, d_elves])\n",
    "whole = whole.drop('cod_spec', axis= 1)\n",
    "whole = whole.drop('equip_cod', axis= 1)\n",
    "whole = whole.dropna()\n",
    "\n",
    "whole.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((43, 12), (43,))"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "whole['cod_unit'] = le.fit_transform(whole['cod_unit'])\n",
    "whole['cod_faction'] = le.fit_transform(whole['cod_faction'])\n",
    "\n",
    "X = whole.iloc[:, 1 : -1]\n",
    "y = whole['cost']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 1 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "lin_model = linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.round(lin_model.predict(X_test))\n",
    "\n",
    "m = confusion_matrix(y_test, y_pred)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "F:\\Python\\Python\\Python_39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_model = logistic.fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.round(logistic.predict(X_test))\n",
    "\n",
    "m = confusion_matrix(y_test, y_pred)\n",
    "print(m)"
   ]
  }
 ]
}