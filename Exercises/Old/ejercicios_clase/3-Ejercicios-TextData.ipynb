{"cells":[{"cell_type":"markdown","metadata":{"id":"fRF_zpUrc02R","colab_type":"text"},"source":["## Cleaning Text\n","\n","Clean white spaces in the text_data"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","\n","wpt = nltk.WordPunctTokenizer()\n","stop_words = nltk.corpus.stopwords.words('english')"]},{"cell_type":"code","metadata":{"id":"Ydk_l4olc02S","colab_type":"code","outputId":"42e6c0bb-defe-4a9d-d409-ded274f2e74a","colab":{}},"source":["text_data = [\"  Interrobang. By aishwarya Henriette    \",\n","            \"Parking And Going. By Karl Gautier\",\n","            \"    Today Is The night. By Jarek Prakash\"]"],"execution_count":62,"outputs":[]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"['Interrobang.ByaishwaryaHenriette',\n 'ParkingAndGoing.ByKarlGautier',\n 'TodayIsThenight.ByJarekPrakash']"},"metadata":{},"execution_count":36}],"source":["text_data1 = text_data\n","for e  in range(len(text_data1)):\n","    text_data[e] = text_data[e].replace(' ', '')\n","text_data1\n","# El Chapucero"]},{"cell_type":"code","metadata":{"id":"lo-z8BKac02X","colab_type":"code","outputId":"12a51476-8abc-45e2-c593-091c4bfe7848","colab":{}},"source":["# strip whitespaces\n","# remove periods\n","# Capitalize the text"],"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"['INTERROBANG BY AISHWARYA HENRIETTE',\n 'PARKING AND GOING BY KARL GAUTIER',\n 'TODAY IS THE NIGHT BY JAREK PRAKASH']"},"metadata":{},"execution_count":95}],"source":["for e in range(len(text_data)):\n","    text_data[e] = re.sub(r\"^\\s+|\\s+$\", \"\", text_data[e])               # removes front and end spaces from string chain\n","    text_data[e] = re.sub(r'[^\\w\\s]','',text_data[e])                   # removes periods\n","    text_data[e] = text_data[e].upper()\n","\n","text_data"]},{"cell_type":"code","metadata":{"id":"0MiMFdpJc02c","colab_type":"code","outputId":"1fddfdc2-16d1-40e4-d08c-48ccb337825f","colab":{}},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['INTERROBANG BY AISHWARYA HENRIETTE',\n"," 'PARKING AND GOING BY KARL GAUTIER',\n"," 'TODAY IS THE NIGHT BY JAREK PRAKASH']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"ROWeB0AMc02e","colab_type":"text"},"source":["### See Also\n","* Beginners Tutorial for Regular Expressions in Python (https://www.analyticsvidhya.com/blog/2015/06/regular-expression-python/)\n","\n","## Parsing and Cleaning HTML\n","Use Beautiful Soup to get the full name in the provided html"]},{"cell_type":"code","metadata":{"id":"Sbc-P4lrc02f","colab_type":"code","outputId":"b0d9319d-5cab-46e4-9573-bd99ecd7182f","colab":{}},"source":["from bs4 import BeautifulSoup\n","\n","html = \"\"\"\n","    <div class='full_name'><span style='font-weight:bold'>Yan</span> Chin</div>\n","\"\"\"\n"],"execution_count":101,"outputs":[]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"'Yan Chin\\n'"},"metadata":{},"execution_count":136}],"source":["soup = BeautifulSoup(html, 'lxml')\n","# print(soup.prettify())\n","soup.find('div', {'class': 'full_name'})\n","soup.text"]},{"cell_type":"markdown","metadata":{"id":"WIWpbryEc02h","colab_type":"text"},"source":["### See Also\n","* Beautiful Soup documentation (https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n","\n","## Removing Punctuation\n","Remove punctuation of the text provided"]},{"cell_type":"code","metadata":{"id":"awi3_C0oc02i","colab_type":"code","outputId":"d1c7046b-3efa-4392-ec1c-ad3cdeb95ad2","colab":{}},"source":["import unicodedata\n","import sys\n","\n","text_data = ['Hi!!! I. Love. This. Song.....', '10000% Agree!!!! #LoveIT', 'Right?!?!']\n","\n","# create a dictionary of punctuation characters\n","# for each string, remove any punctuation characters"],"execution_count":124,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["punct_list =[]\n","punct_dict = {'punctuation': punct_list}"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["punctuation_nuke =  lambda x: re.sub(r'[^\\w\\s]','',x) "]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"},"metadata":{},"execution_count":123}],"source":["for e in range(len(text_data)):\n","   text_data[e] = punctuation_nuke(text_data[e])\n","text_data"]},{"cell_type":"markdown","metadata":{"id":"pFCwwskAc02k","colab_type":"text"},"source":["## Tokenizing Text"]},{"cell_type":"code","metadata":{"id":"S-yH6wBAc02l","colab_type":"code","outputId":"5f286d0f-86ed-4f89-823f-6735d2999464","colab":{}},"source":["from nltk.tokenize import word_tokenize\n","string = \"The science of today is the technology of tommorrow\"\n","\n","# tokenize words\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"mabKWS4qc02o","colab_type":"code","colab":{}},"source":["from nltk.tokenize import sent_tokenize\n","string = \"The science of today is the technology of tommorw. Tommorrow is today\"\n","\n","# tokenize sentences\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SF_ehH1gc02q","colab_type":"text"},"source":["## Removing Stop Words"]},{"cell_type":"code","metadata":{"id":"fsBHzAaXc02q","colab_type":"code","outputId":"6b1fb542-341b-4d69-e72d-dd6b9330e026","colab":{}},"source":["from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n","\n","tokenized_words = ['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', 'and', 'park']\n","\n","stop_words = stopwords.words('english')\n","\n","# remove stop words\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Servando\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Unzipping corpora\\stopwords.zip.\n"}]},{"cell_type":"markdown","metadata":{"id":"e3lJDgR_c02s","colab_type":"text"},"source":["## Stemming Words"]},{"cell_type":"code","metadata":{"id":"gjO9PH7Lc02t","colab_type":"code","colab":{}},"source":["from nltk.stem.porter import PorterStemmer\n","\n","tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n","\n","# create stemmer\n","\n","\n","# apply stemmer\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bfXNBOMEc02v","colab_type":"text"},"source":["### See Also\n","* Porter Stemming Algorithm (https://tartarus.org/martin/PorterStemmer/)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JVwR8z7Nc02w","colab_type":"text"},"source":["\n","\n","## Encoding Text as a Bag of Words"]},{"cell_type":"code","metadata":{"id":"2vcIO4bgc02w","colab_type":"code","outputId":"d83877b9-e5a9-495d-c7e5-6487e94829e3","colab":{}},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","text_data = np.array(['I love Brazil. Brazil!', 'Sweden is best', 'Germany beats both'])\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTN7IIFBc02y","colab_type":"code","outputId":"c867c696-5c75-4842-eac4-dd161d2518f9","colab":{}},"source":["# Convert to array and show the result"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmHD5OYAc021","colab_type":"code","outputId":"3c6b6f2c-94bc-4725-cfd7-3c92b609254a","colab":{}},"source":["# show the feature names\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7tCn8LN_c023","colab_type":"text"},"source":["\n","\n","## Weighting Word Importance"]},{"cell_type":"code","metadata":{"id":"6rH571Vcc023","colab_type":"code","outputId":"7324e952-fd49-4a5a-d3ae-fc78837eacd6","colab":{}},"source":["import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","text_data = np.array(['I love Brazil. Brazil!', 'Sweden is best', 'Germany beats both'])\n","\n","# create the tf-idf feature matrix\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHzH-iuUc025","colab_type":"code","outputId":"c82e2b5a-cd69-4dbf-af9c-fbe2d6ac7aee","colab":{}},"source":["# Convert to array and show the result\n","feature_matrix.toarray()"],"execution_count":14,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'feature_matrix' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-14-4962b22f96ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert to array and show the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mNameError\u001b[0m: name 'feature_matrix' is not defined"]}]},{"cell_type":"code","metadata":{"id":"nlomIjaQc027","colab_type":"code","outputId":"7f67847a-d3d6-49e3-9132-4905877867ee","colab":{}},"source":["# show the vocabulary\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mfIiK37cc02-","colab_type":"text"},"source":["$$\n","tfidf(t, d) = tf(t,d) * idf(t)\n","$$\n","\n","where $t$ is a word\n","\n","$d$ is a document\n","\n","$$\n","idf(t) = log(\\frac{1 + n_d}{1 + df(d, t}) +1\n","$$\n","\n","where $n_d$ is the number of documents and \n","\n","$df(d,t)$ is term, $t$'s document frequency (i.e. number of documents where the term appears)\n","\n","### See Also\n","* scikit-learn documentation: tf-idf term weighting (http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"]},{"cell_type":"code","metadata":{"id":"2OqkDC6wc02-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"colab":{"name":"3-Ejercicios-TextData.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}